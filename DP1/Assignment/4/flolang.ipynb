{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2120badbc98de39b433d8e3b7abaacaf",
     "grade": false,
     "grade_id": "cell-9e78272cc4af091a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "*General hints:* <br>\n",
    "* You may use another notebook to test different approaches and ideas. When complete and mature, turn your code snippets into the requested functions in this notebook for submission. \n",
    "* Make sure the function implementations are generic and can be applied to any dataset (not just the one provided).\n",
    "* Add explanatory code comments in the code cells. Make sure that these comments improve our understanding of your implementation decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ca384ab2b432240f2e75945bb1878249",
     "grade": false,
     "grade_id": "cell-9d52cb434e7f0910",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "-----\n",
    "* Create a variable holding your student id, as shown below. \n",
    "* Simply replace the example (`01234567`) with your actual student id having a total of 8 digits. \n",
    "* Maintain the variable as a string, do NOT change its type in this notebook!\n",
    "* *Note: If your student id has 7 digits, add a leading 0. The final student id MUST have 8 digits!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn = '12213171'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3489966489e6d6c742161745f2e61bc3",
     "grade": false,
     "grade_id": "cell-420b4c449379ffe5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 0. Import\n",
    "\n",
    "Implement a function `tidy` which imports the data set assigned and provided to you as a CSV file into a `pandas` dataframe. Access the data set and establish whether your data set is tidy. If not, clean the data set before continuing with Step 1. Mind all rules of tidying data sets in this step. Make sure you comply to the following statements:\n",
    "* If there is an index column (row numbers) in your tidied dataset, keep it.\n",
    "* The following columns, once identified, correspond to variables 1:1 (no need for transformations):\n",
    "  * `full_name`\n",
    "  * `automotive`\n",
    "  * `color`\n",
    "  * `job`\n",
    "  * `address`\n",
    "  * `coordinates`\n",
    "* The tidied dataset should have a total of 8 columns (not including the index), the first column should be `full_name`.\n",
    "* Mind the intended content of each attribute (e.g. full_name should contain the full name of a person, no need to change that)\n",
    "* If tidy or done, have the function `tidy` return the ready data set as a dataframe.\n",
    "\n",
    "Note that `tidy` must take a single parameter that holds the basename of the CSV file (i.e., the name without file extension). Do NOT change the name of the file, do not overwrite the original data file, and make sure you submit your final ZIP following the [Code of Conduct](https://datascience.ai.wu.ac.at/ws21/dataprocessing1/code_of_conduct.html) requirements. Especially, make sure you put your data file in a folder called `data/` when submitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e96fea9cc9f84652b592c3659339a48b",
     "grade": false,
     "grade_id": "cell-81e21dccd785e63d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0        full_name automotive            color  \\\n",
      "0               Janice Mann   TZK-5163       DarkViolet   \n",
      "1            Alexandra Haas    KIY 037       PowderBlue   \n",
      "2              Jason Arroyo    U09 4JK             Snow   \n",
      "3            Alejandro Hart    W19 9QR        GoldenRod   \n",
      "4             Timothy Baker   40Q 8824           Orange   \n",
      "...                     ...        ...              ...   \n",
      "1619         Tracy Erickson    190-684            Green   \n",
      "1620        Lindsay Osborne    257 ZR8         DarkCyan   \n",
      "1621            John Barton     399GLG  MediumVioletRed   \n",
      "1622            Kayla Russo    88C D74        LightGray   \n",
      "1623              Sara Hall    SPI7199             Lime   \n",
      "\n",
      "Unnamed: 0                            job             address  \\\n",
      "0              Designer, fashion/clothing        Melissahaven   \n",
      "1               Building control surveyor      Rodriguezburgh   \n",
      "2                  Chief Strategy Officer         Gardnerberg   \n",
      "3                              Geochemist            Tranland   \n",
      "4                        Network engineer  South Nataliemouth   \n",
      "...                                   ...                 ...   \n",
      "1619                        Haematologist      Lake Alanhaven   \n",
      "1620                       Hydrogeologist           Ibarraton   \n",
      "1621                            Mudlogger     East Roberttown   \n",
      "1622        Operational investment banker            Erikfurt   \n",
      "1623            Estate manager/land agent        New Kimberly   \n",
      "\n",
      "Unnamed: 0                                       coordinates  \\\n",
      "0               (Decimal('52.183991'), Decimal('67.055665'))   \n",
      "1            (Decimal('-20.4303945'), Decimal('-75.895260'))   \n",
      "2            (Decimal('-51.0134155'), Decimal('107.324399'))   \n",
      "3             (Decimal('78.0828945'), Decimal('-33.302858'))   \n",
      "4               (Decimal('81.551225'), Decimal('-3.628981'))   \n",
      "...                                                      ...   \n",
      "1619          (Decimal('73.2160295'), Decimal('-59.039948'))   \n",
      "1620            (Decimal('23.153734'), Decimal('35.590832'))   \n",
      "1621          (Decimal('-15.993773'), Decimal('158.303118'))   \n",
      "1622        (Decimal('-37.1624925'), Decimal('-153.002489'))   \n",
      "1623           (Decimal('51.003183'), Decimal('164.308323'))   \n",
      "\n",
      "Unnamed: 0            date_time                  full_company_name  \n",
      "0           2005-08-27 02:25:16     886684Arroyo, Brewer and Smith  \n",
      "1           2004-11-28 18:38:06  943086Diaz, Simmons and Robertson  \n",
      "2           2010-03-31 17:21:06   308270Fisher, Robinson and Jones  \n",
      "3           1995-02-07 13:54:19    641452Nguyen, Wright and Taylor  \n",
      "4           2010-11-15 03:10:44     467221Williams, Fox and Thomas  \n",
      "...                         ...                                ...  \n",
      "1619        1997-09-09 03:35:02               548491Cuevas-Beltran  \n",
      "1620        2000-04-19 17:31:04   619146Parker, Green and Humphrey  \n",
      "1621        2002-06-12 03:52:45               064890Russell-Torres  \n",
      "1622        2014-08-16 17:33:50                 428063Mitchell Ltd  \n",
      "1623        2008-07-23 05:59:17             032129Chapman-Thompson  \n",
      "\n",
      "[1624 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def tidy(x):\n",
    "    filePath = f\"./data/{x}.csv\"\n",
    "    data = pd.read_csv(filePath)\n",
    "\n",
    "    # change rows and columns\n",
    "    dataTranspose = data.transpose() # https://www.geeksforgeeks.org/python-pandas-dataframe-transpose/\n",
    "    # select columns and put it in first row\n",
    "    dataTranspose.columns = dataTranspose.iloc[0] # https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html\n",
    "    # delet first row because we do not want two rows with colum names\n",
    "    dataTranspose = dataTranspose.drop(dataTranspose.index[0])\n",
    "\n",
    "    # split the colum date_time/full_company_name in seperate columns\n",
    "    # https://www.delftstack.com/de/howto/python-pandas/split-column-in-python-pandas/\n",
    "    if 'date_time/full_company_name' in dataTranspose.columns:\n",
    "        dataTranspose[['date_time', 'full_company_name']] = dataTranspose['date_time/full_company_name'].str.split(pat=\"\\.\", n=1, expand=True)\n",
    "\n",
    "    # delete colum date_time/full_company_name   \n",
    "    dataTranspose = dataTranspose.drop(columns=['date_time/full_company_name'])\n",
    "    return pd.DataFrame(dataTranspose)\n",
    "\n",
    "print(tidy(mn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "21071c01488e30d64223a1d4cdc68565",
     "grade": true,
     "grade_id": "cell-9a75a2763c7bbe5d",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_equal\n",
    "import pandas\n",
    "assert_equal(type(tidy(mn)), pandas.core.frame.DataFrame)\n",
    "assert_equal(len((tidy(mn)).columns), 8)\n",
    "assert_equal(list((tidy(mn)).columns)[0], \"full_name\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d3420d99ec9378786d1e90b4f41040a3",
     "grade": false,
     "grade_id": "cell-72c2573051ab8535",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "-------\n",
    "## 1. Missing values\n",
    "\n",
    "### 1.1 Code part\n",
    "Implement a function called `missing_values` which takes as an input a dataframe and check if there are any missing values in the dataset. Record the row ids of the observations containing missing values as a list of numbers and make sure that the function returns the recorded list in the end. If there are no missing values, `missing_values` should return an empty list.\n",
    "\n",
    "NOTE: Try to find out how missing values are incoded in your datasest and which missing values occur in your dataset by manual inspection, but at least test for the following: `\"nan\"`,`\"NA\"`,`\"-inf\"`,`\"inf\"`,`\"None\"`; also treat fields containing the numeric value 0 as well as for empty fields and fields containing only white spaces as missing. (We are aware that this test generic test might be overshooting in practice ;-))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c924e80de70e8169cc282686502fb094",
     "grade": false,
     "grade_id": "cell-6d4fb7f2e44e7cfb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9,\n",
       " 31,\n",
       " 63,\n",
       " 71,\n",
       " 93,\n",
       " 118,\n",
       " 150,\n",
       " 177,\n",
       " 221,\n",
       " 344,\n",
       " 361,\n",
       " 369,\n",
       " 461,\n",
       " 512,\n",
       " 579,\n",
       " 595,\n",
       " 603,\n",
       " 706,\n",
       " 718,\n",
       " 804,\n",
       " 833,\n",
       " 913,\n",
       " 967,\n",
       " 969,\n",
       " 1010,\n",
       " 1029,\n",
       " 1037,\n",
       " 1061,\n",
       " 1078,\n",
       " 1102,\n",
       " 1111,\n",
       " 1143,\n",
       " 1227,\n",
       " 1229,\n",
       " 1251,\n",
       " 1258,\n",
       " 1411,\n",
       " 1441,\n",
       " 1454,\n",
       " 1529,\n",
       " 1598]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def missing_values(x):\n",
    "    # replace all missing symbols with NA\n",
    "    missing_symbols = [\"nan\", \"NA\", \"-inf\", \"inf\", \"None\", \"0\", \"\", \"—\", \"--\"]\n",
    "    x.replace(missing_symbols, pd.NA, inplace=True)\n",
    "    \n",
    "    # It searches in every row if there is any missing value. If there is a missing value, it indicates its index and added it to a list\n",
    "    missingRows = x.isna().any(axis=1) # https://pandas.pydata.org/docs/reference/api/pandas.isna.html#pandas.isna\n",
    "    missingRowsList = []\n",
    "    for i in missingRows.index:\n",
    "        if missingRows[i]:\n",
    "            missingRowsList.append(int(i))\n",
    "    return missingRowsList\n",
    "\n",
    "missing_values(tidy(mn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "85bc407053859d1bb9145de1913eae3a",
     "grade": true,
     "grade_id": "cell-4c692eab5b638fc7",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_equal\n",
    "assert_equal(type(missing_values(tidy(mn))), list)\n",
    "assert_equal(all(isinstance(i, int) for i in missing_values(tidy(mn))), True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "52fac7bcbfdfcaea74bdcda572dac51b",
     "grade": false,
     "grade_id": "cell-82f316abfa9423e7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.2. Analytical part\n",
    "\n",
    "* Does the dataset contain missing values?\n",
    "* If no, explain how you proved that this is actually the case.\n",
    "* If yes, describe the discovered missing values. What could be an explanation for their missingness?\n",
    "\n",
    "Write your answer in the markdown cell bellow. Do NOT delete or replace the answer cell with another one!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "229a22e8b0e33f07eb7e3e7a6a652bf2",
     "grade": true,
     "grade_id": "cell-3ad38c6f2d1998f6",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "Yes, the data set contains missing values. These missing values are over 41 rows distributed. There could be several issues for the missingness:\n",
    "    - there could be variables that are not applicable to all objects or some variables are not available at the time of recording\n",
    "    - there could also be some missing values because of errors in data-generation process (MCAR, MAR, MNAR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "828e5a07966e9e14239edd87b539003c",
     "grade": false,
     "grade_id": "cell-87126fc406d941ad",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "------\n",
    "## 2. Handling missing values\n",
    "### 2.1. Code part\n",
    "Apply a (simple) function called *handling_missing_values* for handling missing values using an adequate single-imputation technique  of your choice per type of missing values. Make use of the techniques learned in Unit 4. The function should take as an input a dataframe and return the updated dataframe. Mind the following:\n",
    "- The objective is to apply single imputation on these synthetic data. Do not make up a background story (at this point)!\n",
    "- Do NOT simply drop the missing values. This is not an option.\n",
    "- The imputation technique must be adequate for a given variable type (quantitative, qualitative). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0226044c2b66de952ca20bc64edae12b",
     "grade": false,
     "grade_id": "cell-5ba2dc8b5cbe1f8b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>full_name</th>\n",
       "      <th>automotive</th>\n",
       "      <th>color</th>\n",
       "      <th>job</th>\n",
       "      <th>address</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>date_time</th>\n",
       "      <th>full_company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Janice Mann</td>\n",
       "      <td>TZK-5163</td>\n",
       "      <td>DarkViolet</td>\n",
       "      <td>Designer, fashion/clothing</td>\n",
       "      <td>Melissahaven</td>\n",
       "      <td>(Decimal('52.183991'), Decimal('67.055665'))</td>\n",
       "      <td>2005-08-27 02:25:16</td>\n",
       "      <td>886684Arroyo, Brewer and Smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alexandra Haas</td>\n",
       "      <td>KIY 037</td>\n",
       "      <td>PowderBlue</td>\n",
       "      <td>Building control surveyor</td>\n",
       "      <td>Rodriguezburgh</td>\n",
       "      <td>(Decimal('-20.4303945'), Decimal('-75.895260'))</td>\n",
       "      <td>2004-11-28 18:38:06</td>\n",
       "      <td>943086Diaz, Simmons and Robertson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jason Arroyo</td>\n",
       "      <td>U09 4JK</td>\n",
       "      <td>Snow</td>\n",
       "      <td>Chief Strategy Officer</td>\n",
       "      <td>Gardnerberg</td>\n",
       "      <td>(Decimal('-51.0134155'), Decimal('107.324399'))</td>\n",
       "      <td>2010-03-31 17:21:06</td>\n",
       "      <td>308270Fisher, Robinson and Jones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alejandro Hart</td>\n",
       "      <td>W19 9QR</td>\n",
       "      <td>GoldenRod</td>\n",
       "      <td>Geochemist</td>\n",
       "      <td>Tranland</td>\n",
       "      <td>(Decimal('78.0828945'), Decimal('-33.302858'))</td>\n",
       "      <td>1995-02-07 13:54:19</td>\n",
       "      <td>641452Nguyen, Wright and Taylor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Timothy Baker</td>\n",
       "      <td>40Q 8824</td>\n",
       "      <td>Orange</td>\n",
       "      <td>Network engineer</td>\n",
       "      <td>South Nataliemouth</td>\n",
       "      <td>(Decimal('81.551225'), Decimal('-3.628981'))</td>\n",
       "      <td>2010-11-15 03:10:44</td>\n",
       "      <td>467221Williams, Fox and Thomas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>Tracy Erickson</td>\n",
       "      <td>190-684</td>\n",
       "      <td>Green</td>\n",
       "      <td>Haematologist</td>\n",
       "      <td>Lake Alanhaven</td>\n",
       "      <td>(Decimal('73.2160295'), Decimal('-59.039948'))</td>\n",
       "      <td>1997-09-09 03:35:02</td>\n",
       "      <td>548491Cuevas-Beltran</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>Lindsay Osborne</td>\n",
       "      <td>257 ZR8</td>\n",
       "      <td>DarkCyan</td>\n",
       "      <td>Hydrogeologist</td>\n",
       "      <td>Ibarraton</td>\n",
       "      <td>(Decimal('23.153734'), Decimal('35.590832'))</td>\n",
       "      <td>2000-04-19 17:31:04</td>\n",
       "      <td>619146Parker, Green and Humphrey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>John Barton</td>\n",
       "      <td>399GLG</td>\n",
       "      <td>MediumVioletRed</td>\n",
       "      <td>Mudlogger</td>\n",
       "      <td>East Roberttown</td>\n",
       "      <td>(Decimal('-15.993773'), Decimal('158.303118'))</td>\n",
       "      <td>2002-06-12 03:52:45</td>\n",
       "      <td>064890Russell-Torres</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622</th>\n",
       "      <td>Kayla Russo</td>\n",
       "      <td>88C D74</td>\n",
       "      <td>LightGray</td>\n",
       "      <td>Operational investment banker</td>\n",
       "      <td>Erikfurt</td>\n",
       "      <td>(Decimal('-37.1624925'), Decimal('-153.002489'))</td>\n",
       "      <td>2014-08-16 17:33:50</td>\n",
       "      <td>428063Mitchell Ltd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>Sara Hall</td>\n",
       "      <td>SPI7199</td>\n",
       "      <td>Lime</td>\n",
       "      <td>Estate manager/land agent</td>\n",
       "      <td>New Kimberly</td>\n",
       "      <td>(Decimal('51.003183'), Decimal('164.308323'))</td>\n",
       "      <td>2008-07-23 05:59:17</td>\n",
       "      <td>032129Chapman-Thompson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1624 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Unnamed: 0        full_name automotive            color  \\\n",
       "0               Janice Mann   TZK-5163       DarkViolet   \n",
       "1            Alexandra Haas    KIY 037       PowderBlue   \n",
       "2              Jason Arroyo    U09 4JK             Snow   \n",
       "3            Alejandro Hart    W19 9QR        GoldenRod   \n",
       "4             Timothy Baker   40Q 8824           Orange   \n",
       "...                     ...        ...              ...   \n",
       "1619         Tracy Erickson    190-684            Green   \n",
       "1620        Lindsay Osborne    257 ZR8         DarkCyan   \n",
       "1621            John Barton     399GLG  MediumVioletRed   \n",
       "1622            Kayla Russo    88C D74        LightGray   \n",
       "1623              Sara Hall    SPI7199             Lime   \n",
       "\n",
       "Unnamed: 0                            job             address  \\\n",
       "0              Designer, fashion/clothing        Melissahaven   \n",
       "1               Building control surveyor      Rodriguezburgh   \n",
       "2                  Chief Strategy Officer         Gardnerberg   \n",
       "3                              Geochemist            Tranland   \n",
       "4                        Network engineer  South Nataliemouth   \n",
       "...                                   ...                 ...   \n",
       "1619                        Haematologist      Lake Alanhaven   \n",
       "1620                       Hydrogeologist           Ibarraton   \n",
       "1621                            Mudlogger     East Roberttown   \n",
       "1622        Operational investment banker            Erikfurt   \n",
       "1623            Estate manager/land agent        New Kimberly   \n",
       "\n",
       "Unnamed: 0                                       coordinates  \\\n",
       "0               (Decimal('52.183991'), Decimal('67.055665'))   \n",
       "1            (Decimal('-20.4303945'), Decimal('-75.895260'))   \n",
       "2            (Decimal('-51.0134155'), Decimal('107.324399'))   \n",
       "3             (Decimal('78.0828945'), Decimal('-33.302858'))   \n",
       "4               (Decimal('81.551225'), Decimal('-3.628981'))   \n",
       "...                                                      ...   \n",
       "1619          (Decimal('73.2160295'), Decimal('-59.039948'))   \n",
       "1620            (Decimal('23.153734'), Decimal('35.590832'))   \n",
       "1621          (Decimal('-15.993773'), Decimal('158.303118'))   \n",
       "1622        (Decimal('-37.1624925'), Decimal('-153.002489'))   \n",
       "1623           (Decimal('51.003183'), Decimal('164.308323'))   \n",
       "\n",
       "Unnamed: 0            date_time                  full_company_name  \n",
       "0           2005-08-27 02:25:16     886684Arroyo, Brewer and Smith  \n",
       "1           2004-11-28 18:38:06  943086Diaz, Simmons and Robertson  \n",
       "2           2010-03-31 17:21:06   308270Fisher, Robinson and Jones  \n",
       "3           1995-02-07 13:54:19    641452Nguyen, Wright and Taylor  \n",
       "4           2010-11-15 03:10:44     467221Williams, Fox and Thomas  \n",
       "...                         ...                                ...  \n",
       "1619        1997-09-09 03:35:02               548491Cuevas-Beltran  \n",
       "1620        2000-04-19 17:31:04   619146Parker, Green and Humphrey  \n",
       "1621        2002-06-12 03:52:45               064890Russell-Torres  \n",
       "1622        2014-08-16 17:33:50                 428063Mitchell Ltd  \n",
       "1623        2008-07-23 05:59:17             032129Chapman-Thompson  \n",
       "\n",
       "[1624 rows x 8 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def handling_missing_values(x):\n",
    "    data = x\n",
    "    missing_symbols = [\"nan\", \"NA\", \"-inf\", \"inf\", \"None\", \"0\", \"\", \"—\", \"--\"]\n",
    "    # Replace all missing_symbols in NA\n",
    "    for i in missing_symbols:\n",
    "        data.replace(missing_symbols, pd.NA, inplace=True)\n",
    "    \n",
    "    # If i is numeric, replace missing value with mean\n",
    "    for i in data.columns:\n",
    "        if data[i].dtype in ['int', 'float']:\n",
    "            mean = data[i].mean()\n",
    "            data[i].fillna(mean, inplace=True) # fillna detects missing values: https://pandas.pydata.org/docs/reference/api/pandas.isna.html#pandas.isna\n",
    "        # if i is not numeric, replace value with mode\n",
    "        else:\n",
    "            mode = data[i].mode()[0]\n",
    "            data[i].fillna(mode, inplace=True) # https://pandas.pydata.org/docs/reference/api/pandas.isna.html#pandas.isna\n",
    "    \n",
    "    return data\n",
    "\n",
    "handling_missing_values(tidy(mn)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f4a5257fd57591d9ae8374dc832e2c9a",
     "grade": true,
     "grade_id": "cell-0edce052e98e2e95",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_equal\n",
    "assert_equal(len(missing_values(handling_missing_values(tidy(mn)))), 0)\n",
    "assert_equal(handling_missing_values(tidy(mn)).shape, tidy(mn).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "379b1e101131334e3262e96f723fe8e6",
     "grade": false,
     "grade_id": "cell-c697641b9d5a1c3a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.2. Analytical part\n",
    "Discuss the implications. Answer the following:\n",
    "\n",
    "- How would you qualify the data-generating processes leading to different types of missing values, provided that the data was not synthetic?\n",
    "- What are the benefits and disadvantages of the chosen single-imputation technique?\n",
    "- How would you apply a multiple-imputation technique to one type of missing values, if applicable at all?\n",
    "- We asked you to test for/treat as missing values by checking certain field values, as well as empty fields or fields containing the numeric value 0... what are potential problems of this heuristics?\n",
    "\n",
    "Write your answer in the markdown cell bellow. Do NOT delete or replace the answer cell with another one!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "34f9ca681c722ebe151d6fac42d71b25",
     "grade": true,
     "grade_id": "cell-5c05456587f2ff17",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "For each different type of missing values we have to handle the missingness different. Missing Not at Random is the most challenging type.\n",
    "Benefits: They are easy to implement.\n",
    "Disadvantage: They do not reflect the variance in (\"real\") datasets without missing values.\n",
    "Multiple imputation technique is effective when the data is MCAR or MAR. At first we have to create multiple complete datasets. Missing values will be replaced with plausible values for example with predictive mean matching. Then the analysis is then performed for each imputed dataset. The combined statistic is then computed.\n",
    "Potentials problems that comes up with replacing values that are 0 are that we do not know if these values are actual correct observed. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dfaf0570a8a70924b35ef279df754c19",
     "grade": false,
     "grade_id": "cell-573d56d6699b84eb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "-----\n",
    "## 3. Duplicate entries\n",
    "Implement a function called `duplicates` that takes as an input a (tidy) dataframe `x`. Assume that `duplicates` receives a dataframe as returned from your Step 0 implementation of `tidy`. It then checks whether there are any duplicates in the dataset. Record the row ids of the observations being duplicates and have `duplicates` returns the list in the end. An empty list indicates the absence of duplicated observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5d3199cb48685917455f085c8d366844",
     "grade": false,
     "grade_id": "cell-7954cffea933a812",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['66', '67', '76', '77', '189', '190', '232', '233', '246', '247', '303', '304', '322', '323', '400', '401', '433', '434', '458', '459', '495', '496', '551', '552', '559', '560', '614', '615', '681', '682', '691', '692', '778', '779', '838', '839', '845', '846', '857', '858', '864', '865', '874', '875', '917', '918', '944', '945', '954', '955', '1130', '1131', '1134', '1135', '1210', '1211', '1241', '1242', '1261', '1262', '1305', '1306', '1310', '1311', '1317', '1318', '1353', '1354', '1366', '1367', '1375', '1376', '1382', '1383', '1438', '1439', '1487', '1488', '1567', '1568', '1582', '1583', '1600', '1601']\n"
     ]
    }
   ],
   "source": [
    "def duplicates(x):\n",
    "    # get all dublicates as True\n",
    "    duplicate = x.duplicated(keep=False) # https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.duplicated.html\n",
    "    # return a list of dublicated index\n",
    "    return x.index[duplicate].tolist()\n",
    "\n",
    "print(duplicates(tidy(mn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "81f1ddaa2595165edcbe3c3848bf1880",
     "grade": true,
     "grade_id": "cell-583bc8ab4ba38aa6",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_equal\n",
    "assert_equal(type(duplicates(tidy(mn))), list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8078773ced981185cbbd33775ad95033",
     "grade": false,
     "grade_id": "cell-b04e3f6689a78a44",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "-----\n",
    "## 4. Handling duplicate entries\n",
    "### 4.1. Code part\n",
    "Implement a function called `handling_duplicate_entries` for handling duplicate entries. Again, the function is assumed to receive a tidied data set as obtained from Step 0. It deduplicates the tidy data set. The function then returns the dataframe without duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "612e2d5322a7c96c67c1405ff80ebb36",
     "grade": false,
     "grade_id": "cell-f593e79eae8f4227",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>full_name</th>\n",
       "      <th>automotive</th>\n",
       "      <th>color</th>\n",
       "      <th>job</th>\n",
       "      <th>address</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>date_time</th>\n",
       "      <th>full_company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-inf</td>\n",
       "      <td>5CG8993</td>\n",
       "      <td>Aquamarine</td>\n",
       "      <td>Mining engineer</td>\n",
       "      <td>Patriciaberg</td>\n",
       "      <td>(Decimal('-30.901764'), Decimal('130.963991'))</td>\n",
       "      <td>2021-08-02 03:46:44</td>\n",
       "      <td>619691Ball Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-inf</td>\n",
       "      <td>865-WVK</td>\n",
       "      <td>Peru</td>\n",
       "      <td>Forensic scientist</td>\n",
       "      <td>Port Todd</td>\n",
       "      <td>(Decimal('-23.7939645'), Decimal('-66.604842'))</td>\n",
       "      <td>1994-12-28 16:10:42</td>\n",
       "      <td>429847Johnson-Harris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aaron Atkinson</td>\n",
       "      <td>648 8774</td>\n",
       "      <td>OldLace</td>\n",
       "      <td>Building control surveyor</td>\n",
       "      <td>Alvaradofort</td>\n",
       "      <td>(Decimal('72.2648865'), Decimal('35.123363'))</td>\n",
       "      <td>2015-06-11 09:01:31</td>\n",
       "      <td>801119Daniels-Ward</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aaron Lopez</td>\n",
       "      <td>TAH 931</td>\n",
       "      <td>Gainsboro</td>\n",
       "      <td>Health and safety adviser</td>\n",
       "      <td>Michellemouth</td>\n",
       "      <td>(Decimal('-19.7863615'), Decimal('136.337420'))</td>\n",
       "      <td>2015-02-08 17:05:46</td>\n",
       "      <td>533016Harris Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abigail Bailey</td>\n",
       "      <td>440HNJ</td>\n",
       "      <td>DarkGray</td>\n",
       "      <td>Lexicographer</td>\n",
       "      <td>Port Gregory</td>\n",
       "      <td>(Decimal('-56.2017425'), Decimal('-82.610075'))</td>\n",
       "      <td>2006-04-30 12:54:53</td>\n",
       "      <td>018433Wiggins-Cain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>Zachary Ward</td>\n",
       "      <td>961 1GN</td>\n",
       "      <td>LightGray</td>\n",
       "      <td>Careers information officer</td>\n",
       "      <td>Jasmineland</td>\n",
       "      <td>(Decimal('-4.498669'), Decimal('-149.037765'))</td>\n",
       "      <td>2006-07-04 01:42:32</td>\n",
       "      <td>073461Dunn-Mann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>—</td>\n",
       "      <td>88A 5825</td>\n",
       "      <td>LightCoral</td>\n",
       "      <td>Herbalist</td>\n",
       "      <td>Marquezstad</td>\n",
       "      <td>(Decimal('-47.481363'), Decimal('-134.215281'))</td>\n",
       "      <td>2001-11-13 07:48:04</td>\n",
       "      <td>498836Jackson, Acosta and Moreno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3G 8848C</td>\n",
       "      <td>GreenYellow</td>\n",
       "      <td>Public affairs consultant</td>\n",
       "      <td>North Crystal</td>\n",
       "      <td>(Decimal('-25.696378'), Decimal('50.191305'))</td>\n",
       "      <td>2004-07-14 11:49:37</td>\n",
       "      <td>401208Sandoval, Henry and Zamora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4529</td>\n",
       "      <td>MistyRose</td>\n",
       "      <td>Lighting technician, broadcasting/film/video</td>\n",
       "      <td>New Anthonyton</td>\n",
       "      <td>(Decimal('47.670012'), Decimal('101.261321'))</td>\n",
       "      <td>2006-05-17 12:57:03</td>\n",
       "      <td>604746Johnston-Figueroa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ZP1 R7U</td>\n",
       "      <td>Chocolate</td>\n",
       "      <td>Adult guidance worker</td>\n",
       "      <td>Perkinsbury</td>\n",
       "      <td>(Decimal('69.153548'), Decimal('-12.902170'))</td>\n",
       "      <td>2003-05-21 14:48:04</td>\n",
       "      <td>703882Thomas Group</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1582 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Unnamed: 0       full_name automotive        color  \\\n",
       "0                     -inf    5CG8993   Aquamarine   \n",
       "1                     -inf    865-WVK         Peru   \n",
       "2           Aaron Atkinson   648 8774      OldLace   \n",
       "3              Aaron Lopez    TAH 931    Gainsboro   \n",
       "4           Abigail Bailey     440HNJ     DarkGray   \n",
       "...                    ...        ...          ...   \n",
       "1577          Zachary Ward    961 1GN    LightGray   \n",
       "1578                     —   88A 5825   LightCoral   \n",
       "1579                   NaN   3G 8848C  GreenYellow   \n",
       "1580                   NaN       4529    MistyRose   \n",
       "1581                   NaN    ZP1 R7U    Chocolate   \n",
       "\n",
       "Unnamed: 0                                           job         address  \\\n",
       "0                                        Mining engineer    Patriciaberg   \n",
       "1                                     Forensic scientist       Port Todd   \n",
       "2                              Building control surveyor    Alvaradofort   \n",
       "3                              Health and safety adviser   Michellemouth   \n",
       "4                                          Lexicographer    Port Gregory   \n",
       "...                                                  ...             ...   \n",
       "1577                         Careers information officer     Jasmineland   \n",
       "1578                                           Herbalist     Marquezstad   \n",
       "1579                           Public affairs consultant   North Crystal   \n",
       "1580        Lighting technician, broadcasting/film/video  New Anthonyton   \n",
       "1581                               Adult guidance worker     Perkinsbury   \n",
       "\n",
       "Unnamed: 0                                      coordinates  \\\n",
       "0            (Decimal('-30.901764'), Decimal('130.963991'))   \n",
       "1           (Decimal('-23.7939645'), Decimal('-66.604842'))   \n",
       "2             (Decimal('72.2648865'), Decimal('35.123363'))   \n",
       "3           (Decimal('-19.7863615'), Decimal('136.337420'))   \n",
       "4           (Decimal('-56.2017425'), Decimal('-82.610075'))   \n",
       "...                                                     ...   \n",
       "1577         (Decimal('-4.498669'), Decimal('-149.037765'))   \n",
       "1578        (Decimal('-47.481363'), Decimal('-134.215281'))   \n",
       "1579          (Decimal('-25.696378'), Decimal('50.191305'))   \n",
       "1580          (Decimal('47.670012'), Decimal('101.261321'))   \n",
       "1581          (Decimal('69.153548'), Decimal('-12.902170'))   \n",
       "\n",
       "Unnamed: 0            date_time                 full_company_name  \n",
       "0           2021-08-02 03:46:44                  619691Ball Group  \n",
       "1           1994-12-28 16:10:42              429847Johnson-Harris  \n",
       "2           2015-06-11 09:01:31                801119Daniels-Ward  \n",
       "3           2015-02-08 17:05:46                  533016Harris Inc  \n",
       "4           2006-04-30 12:54:53                018433Wiggins-Cain  \n",
       "...                         ...                               ...  \n",
       "1577        2006-07-04 01:42:32                   073461Dunn-Mann  \n",
       "1578        2001-11-13 07:48:04  498836Jackson, Acosta and Moreno  \n",
       "1579        2004-07-14 11:49:37  401208Sandoval, Henry and Zamora  \n",
       "1580        2006-05-17 12:57:03           604746Johnston-Figueroa  \n",
       "1581        2003-05-21 14:48:04                703882Thomas Group  \n",
       "\n",
       "[1582 rows x 8 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def handling_duplicate_entries(x):\n",
    "    data = x\n",
    "    \n",
    "    # get sorted data list\n",
    "    dataList = sorted(data.values.tolist(), key = str)\n",
    "    \n",
    "    newData = []\n",
    "    \n",
    "    #compare every column\n",
    "    for i in range(len(dataList)):    \n",
    "        if i == 0 or dataList[i] != dataList[i-1]:\n",
    "            newData.append(dataList[i])\n",
    "            \n",
    "    return pd.DataFrame(newData, columns=data.columns)\n",
    "\n",
    "handling_duplicate_entries(tidy(mn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "10bdb20c5d61c818cc5ff269c76ccb62",
     "grade": true,
     "grade_id": "cell-231217b55b6ef843",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_equal\n",
    "assert_equal(len(duplicates(handling_duplicate_entries(tidy(mn)))), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fb5d1538ad19f872fb94d62d81a42f23",
     "grade": false,
     "grade_id": "cell-8c4530b128b5c186",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 4.2. Analytical part\n",
    "Discuss the implications. \n",
    "\n",
    "- What are the benefits and disadvantages of the chosen duplicate definition and the chosen duplicate-handling technique?\n",
    "- Name and explain one alternative definition of (intra-source) duplicates for the given dataset!\n",
    "\n",
    "Write your answer in the markdown cell bellow. Do NOT delete or replace the answer cell with another one!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9e93305db24e2fc3800f252b797c2ad7",
     "grade": true,
     "grade_id": "cell-254db63097c3ed40",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "It takes a lot of memory to store the entire dataset during sorting process, however it is very easy to implement and to understand the code.\n",
    "Intra-source duplicates specifically refers to observations that are duplicated or repeated within the same dataset like in column 66. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
