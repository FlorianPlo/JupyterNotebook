{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2120badbc98de39b433d8e3b7abaacaf",
     "grade": false,
     "grade_id": "cell-9e78272cc4af091a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "*General hints:* <br>\n",
    "* You may use another notebook to test different approaches and ideas. When complete and mature, turn your code snippets into the requested functions in this notebook for submission. \n",
    "* Make sure the function implementations are generic and can be applied to any dataset (not just the one provided).\n",
    "* Add explanatory code comments in the code cells. Make sure that these comments improve our understanding of your implementation decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ca384ab2b432240f2e75945bb1878249",
     "grade": false,
     "grade_id": "cell-9d52cb434e7f0910",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "-----\n",
    "* Create a variable holding your student id, as shown below. \n",
    "* Simply replace the example (`01234567`) with your actual student id having a total of 8 digits. \n",
    "* Maintain the variable as a string, do NOT change its type in this notebook!\n",
    "* *Note: If your student id has 7 digits, add a leading 0. The final student id MUST have 8 digits!*"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T11:25:13.734643Z",
     "start_time": "2024-05-13T11:25:13.725066Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "mn = '12209427'\n",
    "mnFlo = \"12213171\""
   ],
   "outputs": [],
   "execution_count": 106
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3489966489e6d6c742161745f2e61bc3",
     "grade": false,
     "grade_id": "cell-420b4c449379ffe5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 0. Import\n",
    "\n",
    "Implement a function `tidy` which imports the data set assigned and provided to you as a CSV file into a `pandas` dataframe. Access the data set and establish whether your data set is tidy. If not, clean the data set before continuing with Step 1. Mind all rules of tidying data sets in this step. Make sure you comply to the following statements:\n",
    "* If there is an index column (row numbers) in your tidied dataset, keep it.\n",
    "* The following columns, once identified, correspond to variables 1:1 (no need for transformations):\n",
    "  * `full_name`\n",
    "  * `automotive`\n",
    "  * `color`\n",
    "  * `job`\n",
    "  * `address`\n",
    "  * `coordinates`\n",
    "* The tidied dataset should have a total of 8 columns (not including the index), the first column should be `full_name`.\n",
    "* Mind the intended content of each attribute (e.g. full_name should contain the full name of a person, no need to change that)\n",
    "* If tidy or done, have the function `tidy` return the ready data set as a dataframe.\n",
    "\n",
    "Note that `tidy` must take a single parameter that holds the basename of the CSV file (i.e., the name without file extension). Do NOT change the name of the file, do not overwrite the original data file, and make sure you submit your final ZIP following the [Code of Conduct](https://datascience.ai.wu.ac.at/ws21/dataprocessing1/code_of_conduct.html) requirements. Especially, make sure you put your data file in a folder called `data/` when submitting."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e96fea9cc9f84652b592c3659339a48b",
     "grade": false,
     "grade_id": "cell-81e21dccd785e63d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-13T11:25:15.462683Z",
     "start_time": "2024-05-13T11:25:15.203558Z"
    }
   },
   "source": [
    "\n",
    "mn = '12209427'\n",
    "\n",
    "# Function to split the merged values into separate\n",
    "def split_digit_text(value):\n",
    "    # Iterate over the string backwards + find the first occurrence where a digit is. This helps to separate because it corresponds to the structure of the values \n",
    "    for i in range(len(value), 1, -1):\n",
    "        if value[i-1].isdigit():\n",
    "            return value[:i], value[i:]  # Return the split parts as a tuple\n",
    "    for element in [\"None\", \"NaN\", \"NA\", \"-inf\"]:\n",
    "        if element in value:\n",
    "            value = value.replace(element, \"\")\n",
    "    return value, None  # Return the whole string and None if no splitting point is found\n",
    "\n",
    "def split_digit_text_real(value):\n",
    "    for element in [\"None\", \"NaN\", \"NA\", \"-inf\"]:\n",
    "        if element in value:\n",
    "            value = value.replace(element, \"\")\n",
    "            if value[0].isalpha():\n",
    "                return None, value\n",
    "    if len(value) > 26 and value[0].isdigit():\n",
    "        return value[:26], value[26:]\n",
    "    if value[0].isalpha():\n",
    "        return None, value\n",
    "    return value, None\n",
    "\n",
    "def tidy(file_name):\n",
    "    \n",
    "    file_path = f\"./data/{file_name}.csv\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    column_names = [\"full_name\", \"automotive\", \"color\", \"job\", \"address\", \"coordinates\"]\n",
    "    # Save temporary first_column values of the csv file\n",
    "    first_col = df[df.columns[0]]\n",
    "\n",
    "    \n",
    "    # Check if the column names given are in the first column using not .isdisjoint(). True if value is in both sets (-> wrong orientation) and then transpose df\n",
    "    if not set(column_names).isdisjoint(first_col):\n",
    "        # transpose df\n",
    "        df = df.transpose()\n",
    "        # assign the column values to the values found in the first column before transposing \n",
    "        df.columns = first_col\n",
    "        # remove the unnecessary first row (same as the headers)\n",
    "        df = df.drop(df.index[0])\n",
    "\n",
    "    # Check if dataset has 8 columns \n",
    "    if len(df.columns) < 8:\n",
    "        # Find the faulty column\n",
    "        special_col = set(df.columns).difference(set(column_names))\n",
    "        # If there is only one special column transform it into a string\n",
    "        if len(special_col) == 1:\n",
    "            special_col = special_col.pop()\n",
    "        # Separate it by it delimiter\n",
    "        two_col = special_col.split(\"/\")\n",
    "        # Create two new df columns with the seperated column names and apply a function split_digit_text to separate all the values and assign it correspondingly \n",
    "        df[two_col[0]], df[two_col[1]] = zip(*df[special_col].apply(split_digit_text_real))\n",
    "        # Drop the faulty column\n",
    "        df.drop(columns=special_col, inplace=True)\n",
    "        \n",
    "        \n",
    "    df.to_csv(\"test2.csv\", index=False, header=True)\n",
    "        \n",
    "    return df\n",
    "    #raise NotImplementedError()\n",
    "    \n",
    "tidy(mn)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0         full_name automotive            color  \\\n",
       "0              Krystal Davis   8M W8036             Pink   \n",
       "1                 Troy Bates   XAK-6038   LightSteelBlue   \n",
       "2           Wendy Mclaughlin    GKT-232          DimGray   \n",
       "3           Wendy Mclaughlin    GKT-232          DimGray   \n",
       "4                 John Baker     512ZXI          DimGray   \n",
       "...                      ...        ...              ...   \n",
       "1638            Bobby Walker   SSY-9653  MediumSlateBlue   \n",
       "1639            Kelli Mendez    859 4VX      GreenYellow   \n",
       "1640           Thomas Martin    821-UWR            Coral   \n",
       "1641           Thomas Martin    821-UWR    PaleTurquoise   \n",
       "1642               Karen Ray    33ZW244      LightYellow   \n",
       "\n",
       "Unnamed: 0                                   job         address  \\\n",
       "0                         Surveyor, hydrographic      Lake Daisy   \n",
       "1                            Exhibition designer  North Nicholas   \n",
       "2                Engineer, manufacturing systems  Elizabethshire   \n",
       "3                Engineer, manufacturing systems  Elizabethshire   \n",
       "4                        Engineer, manufacturing        Leviside   \n",
       "...                                          ...             ...   \n",
       "1638                                  Aid worker        New Mary   \n",
       "1639                        Broadcast journalist  North Leahtown   \n",
       "1640                               Acupuncturist       Harthaven   \n",
       "1641               Operational investment banker      Tashaville   \n",
       "1642        International aid/development worker     Donaldhaven   \n",
       "\n",
       "Unnamed: 0                                       coordinates  \\\n",
       "0              (Decimal('-45.319194'), Decimal('38.284592'))   \n",
       "1             (Decimal('-0.6010165'), Decimal('-70.820681'))   \n",
       "2               (Decimal('89.773312'), Decimal('80.017969'))   \n",
       "3               (Decimal('89.773312'), Decimal('80.017969'))   \n",
       "4            (Decimal('-45.416844'), Decimal('-126.202879'))   \n",
       "...                                                      ...   \n",
       "1638          (Decimal('-30.624984'), Decimal('147.954761'))   \n",
       "1639         (Decimal('-58.7188165'), Decimal('-22.493165'))   \n",
       "1640          (Decimal('-85.283186'), Decimal('160.768683'))   \n",
       "1641        (Decimal('-23.2748715'), Decimal('-164.678235'))   \n",
       "1642          (Decimal('84.4207035'), Decimal('-40.601803'))   \n",
       "\n",
       "Unnamed: 0                   date_time         full_company_name  \n",
       "0           2002-05-18 18:47:18.897635          Daniels-Morrison  \n",
       "1           2021-04-23 13:59:11.274829              Summers-Carr  \n",
       "2           2003-07-12 12:07:18.002811               Peck-Rivera  \n",
       "3           2003-07-12 12:07:18.002811               Peck-Rivera  \n",
       "4           2014-10-17 02:00:58.991156     Davis, Rowe and Brown  \n",
       "...                                ...                       ...  \n",
       "1638        2011-02-16 11:01:56.965545                Knight LLC  \n",
       "1639        2015-05-04 20:37:26.764907  Carter, Martin and Brown  \n",
       "1640        2019-08-16 08:35:16.371470             Hinton-Turner  \n",
       "1641        2010-09-10 19:23:53.914442            Martinez Group  \n",
       "1642        2007-07-15 13:41:56.633100   Taylor, Allen and Potts  \n",
       "\n",
       "[1643 rows x 8 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>full_name</th>\n",
       "      <th>automotive</th>\n",
       "      <th>color</th>\n",
       "      <th>job</th>\n",
       "      <th>address</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>date_time</th>\n",
       "      <th>full_company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Krystal Davis</td>\n",
       "      <td>8M W8036</td>\n",
       "      <td>Pink</td>\n",
       "      <td>Surveyor, hydrographic</td>\n",
       "      <td>Lake Daisy</td>\n",
       "      <td>(Decimal('-45.319194'), Decimal('38.284592'))</td>\n",
       "      <td>2002-05-18 18:47:18.897635</td>\n",
       "      <td>Daniels-Morrison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Troy Bates</td>\n",
       "      <td>XAK-6038</td>\n",
       "      <td>LightSteelBlue</td>\n",
       "      <td>Exhibition designer</td>\n",
       "      <td>North Nicholas</td>\n",
       "      <td>(Decimal('-0.6010165'), Decimal('-70.820681'))</td>\n",
       "      <td>2021-04-23 13:59:11.274829</td>\n",
       "      <td>Summers-Carr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wendy Mclaughlin</td>\n",
       "      <td>GKT-232</td>\n",
       "      <td>DimGray</td>\n",
       "      <td>Engineer, manufacturing systems</td>\n",
       "      <td>Elizabethshire</td>\n",
       "      <td>(Decimal('89.773312'), Decimal('80.017969'))</td>\n",
       "      <td>2003-07-12 12:07:18.002811</td>\n",
       "      <td>Peck-Rivera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wendy Mclaughlin</td>\n",
       "      <td>GKT-232</td>\n",
       "      <td>DimGray</td>\n",
       "      <td>Engineer, manufacturing systems</td>\n",
       "      <td>Elizabethshire</td>\n",
       "      <td>(Decimal('89.773312'), Decimal('80.017969'))</td>\n",
       "      <td>2003-07-12 12:07:18.002811</td>\n",
       "      <td>Peck-Rivera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John Baker</td>\n",
       "      <td>512ZXI</td>\n",
       "      <td>DimGray</td>\n",
       "      <td>Engineer, manufacturing</td>\n",
       "      <td>Leviside</td>\n",
       "      <td>(Decimal('-45.416844'), Decimal('-126.202879'))</td>\n",
       "      <td>2014-10-17 02:00:58.991156</td>\n",
       "      <td>Davis, Rowe and Brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>Bobby Walker</td>\n",
       "      <td>SSY-9653</td>\n",
       "      <td>MediumSlateBlue</td>\n",
       "      <td>Aid worker</td>\n",
       "      <td>New Mary</td>\n",
       "      <td>(Decimal('-30.624984'), Decimal('147.954761'))</td>\n",
       "      <td>2011-02-16 11:01:56.965545</td>\n",
       "      <td>Knight LLC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639</th>\n",
       "      <td>Kelli Mendez</td>\n",
       "      <td>859 4VX</td>\n",
       "      <td>GreenYellow</td>\n",
       "      <td>Broadcast journalist</td>\n",
       "      <td>North Leahtown</td>\n",
       "      <td>(Decimal('-58.7188165'), Decimal('-22.493165'))</td>\n",
       "      <td>2015-05-04 20:37:26.764907</td>\n",
       "      <td>Carter, Martin and Brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1640</th>\n",
       "      <td>Thomas Martin</td>\n",
       "      <td>821-UWR</td>\n",
       "      <td>Coral</td>\n",
       "      <td>Acupuncturist</td>\n",
       "      <td>Harthaven</td>\n",
       "      <td>(Decimal('-85.283186'), Decimal('160.768683'))</td>\n",
       "      <td>2019-08-16 08:35:16.371470</td>\n",
       "      <td>Hinton-Turner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1641</th>\n",
       "      <td>Thomas Martin</td>\n",
       "      <td>821-UWR</td>\n",
       "      <td>PaleTurquoise</td>\n",
       "      <td>Operational investment banker</td>\n",
       "      <td>Tashaville</td>\n",
       "      <td>(Decimal('-23.2748715'), Decimal('-164.678235'))</td>\n",
       "      <td>2010-09-10 19:23:53.914442</td>\n",
       "      <td>Martinez Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1642</th>\n",
       "      <td>Karen Ray</td>\n",
       "      <td>33ZW244</td>\n",
       "      <td>LightYellow</td>\n",
       "      <td>International aid/development worker</td>\n",
       "      <td>Donaldhaven</td>\n",
       "      <td>(Decimal('84.4207035'), Decimal('-40.601803'))</td>\n",
       "      <td>2007-07-15 13:41:56.633100</td>\n",
       "      <td>Taylor, Allen and Potts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1643 rows × 8 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 107
  },
  {
   "cell_type": "code",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "21071c01488e30d64223a1d4cdc68565",
     "grade": true,
     "grade_id": "cell-9a75a2763c7bbe5d",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-13T11:25:16.716934Z",
     "start_time": "2024-05-13T11:25:15.601308Z"
    }
   },
   "source": [
    "from nose.tools import assert_equal\n",
    "import pandas\n",
    "assert_equal(type(tidy(mn)), pandas.core.frame.DataFrame)\n",
    "assert_equal(len((tidy(mn)).columns), 8)\n",
    "assert_equal(list((tidy(mn)).columns)[0], \"full_name\")\n"
   ],
   "outputs": [],
   "execution_count": 108
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d3420d99ec9378786d1e90b4f41040a3",
     "grade": false,
     "grade_id": "cell-72c2573051ab8535",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "-------\n",
    "## 1. Missing values\n",
    "\n",
    "### 1.1 Code part\n",
    "Implement a function called `missing_values` which takes as an input a dataframe and check if there are any missing values in the dataset. Record the row ids of the observations containing missing values as a list of numbers and make sure that the function returns the recorded list in the end. If there are no missing values, `missing_values` should return an empty list.\n",
    "\n",
    "NOTE: Try to find out how missing values are incoded in your datasest and which missing values occur in your dataset by manual inspection, but at least test for the following: `\"nan\"`,`\"NA\"`,`\"-inf\"`,`\"inf\"`,`\"None\"`; also treat fields containing the numeric value 0 as well as for empty fields and fields containing only white spaces as missing. (We are aware that this test generic test might be overshooting in practice ;-))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c924e80de70e8169cc282686502fb094",
     "grade": false,
     "grade_id": "cell-6d4fb7f2e44e7cfb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-13T11:25:17.195902Z",
     "start_time": "2024-05-13T11:25:17.162836Z"
    }
   },
   "source": [
    "def missing_values(df):\n",
    "\n",
    "    l = []\n",
    "    \n",
    "    # define a frozenset with the possible elements which could indicate that the value is missing (manual inspection) \n",
    "    missing_val = frozenset({\"nan\", \"nan\", \"NaN\", \"NA\", \"None\", None, \"-inf\", \"inf\", \"0\", \"--\", \"—\"})\n",
    "    # iterate over each row and create a temporary list with the values of each row with corresponding index\n",
    "    for row in df.itertuples():\n",
    "        current_row = list(row)\n",
    "        # convert the elements of each list of rows to string because there were values which are defined in NumPy such as nan. This got transformed into a string to target it: \"nan\"\n",
    "        string_current_row = list(map(str, current_row))\n",
    "        if set(string_current_row[1:]).intersection(missing_val):\n",
    "            l.append(current_row[0])\n",
    "    \n",
    "    # transform all the string indexes into integer\n",
    "    l = map(int, l)\n",
    "    return list(l)\n",
    " \n",
    "    #raise NotImplementedError()\n",
    "    "
   ],
   "outputs": [],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T11:25:17.656688Z",
     "start_time": "2024-05-13T11:25:17.332105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "missing_values(tidy(mnFlo))\n",
    "\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9,\n",
       " 31,\n",
       " 63,\n",
       " 71,\n",
       " 93,\n",
       " 118,\n",
       " 150,\n",
       " 153,\n",
       " 177,\n",
       " 221,\n",
       " 344,\n",
       " 361,\n",
       " 369,\n",
       " 375,\n",
       " 428,\n",
       " 461,\n",
       " 512,\n",
       " 579,\n",
       " 595,\n",
       " 603,\n",
       " 706,\n",
       " 718,\n",
       " 734,\n",
       " 804,\n",
       " 814,\n",
       " 833,\n",
       " 913,\n",
       " 967,\n",
       " 969,\n",
       " 1010,\n",
       " 1029,\n",
       " 1037,\n",
       " 1061,\n",
       " 1078,\n",
       " 1102,\n",
       " 1111,\n",
       " 1143,\n",
       " 1227,\n",
       " 1229,\n",
       " 1251,\n",
       " 1258,\n",
       " 1411,\n",
       " 1441,\n",
       " 1454,\n",
       " 1529,\n",
       " 1598]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 110
  },
  {
   "cell_type": "code",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "85bc407053859d1bb9145de1913eae3a",
     "grade": true,
     "grade_id": "cell-4c692eab5b638fc7",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-13T11:25:18.435542Z",
     "start_time": "2024-05-13T11:25:17.884345Z"
    }
   },
   "source": [
    "from nose.tools import assert_equal\n",
    "assert_equal(type(missing_values(tidy(mn))), list)\n",
    "assert_equal(all(isinstance(i, int) for i in missing_values(tidy(mn))), True)\n"
   ],
   "outputs": [],
   "execution_count": 111
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "52fac7bcbfdfcaea74bdcda572dac51b",
     "grade": false,
     "grade_id": "cell-82f316abfa9423e7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.2. Analytical part\n",
    "\n",
    "* Does the dataset contain missing values?\n",
    "* If no, explain how you proved that this is actually the case.\n",
    "* If yes, describe the discovered missing values. What could be an explanation for their missingness?\n",
    "\n",
    "Write your answer in the markdown cell bellow. Do NOT delete or replace the answer cell with another one!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "229a22e8b0e33f07eb7e3e7a6a652bf2",
     "grade": true,
     "grade_id": "cell-3ad38c6f2d1998f6",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "828e5a07966e9e14239edd87b539003c",
     "grade": false,
     "grade_id": "cell-87126fc406d941ad",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "------\n",
    "## 2. Handling missing values\n",
    "### 2.1. Code part\n",
    "Apply a (simple) function called *handling_missing_values* for handling missing values using an adequate single-imputation technique  of your choice per type of missing values. Make use of the techniques learned in Unit 4. The function should take as an input a dataframe and return the updated dataframe. Mind the following:\n",
    "- The objective is to apply single imputation on these synthetic data. Do not make up a background story (at this point)!\n",
    "- Do NOT simply drop the missing values. This is not an option.\n",
    "- The imputation technique must be adequate for a given variable type (quantitative, qualitative). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0226044c2b66de952ca20bc64edae12b",
     "grade": false,
     "grade_id": "cell-5ba2dc8b5cbe1f8b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def handling_missing_values(x):\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # SEE SLIDES 4 4 4 4 4 4\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f4a5257fd57591d9ae8374dc832e2c9a",
     "grade": true,
     "grade_id": "cell-0edce052e98e2e95",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_equal\n",
    "assert_equal(len(missing_values(handling_missing_values(tidy(mn)))), 0)\n",
    "assert_equal(handling_missing_values(tidy(mn)).shape, tidy(mn).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "379b1e101131334e3262e96f723fe8e6",
     "grade": false,
     "grade_id": "cell-c697641b9d5a1c3a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.2. Analytical part\n",
    "Discuss the implications. Answer the following:\n",
    "\n",
    "- How would you qualify the data-generating processes leading to different types of missing values, provided that the data was not synthetic?\n",
    "- What are the benefits and disadvantages of the chosen single-imputation technique?\n",
    "- How would you apply a multiple-imputation technique to one type of missing values, if applicable at all?\n",
    "- We asked you to test for/treat as missing values by checking certain field values, as well as empty fields or fields containing the numeric value 0... what are potential problems of this heuristics?\n",
    "\n",
    "Write your answer in the markdown cell bellow. Do NOT delete or replace the answer cell with another one!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "34f9ca681c722ebe151d6fac42d71b25",
     "grade": true,
     "grade_id": "cell-5c05456587f2ff17",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dfaf0570a8a70924b35ef279df754c19",
     "grade": false,
     "grade_id": "cell-573d56d6699b84eb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "-----\n",
    "## 3. Duplicate entries\n",
    "Implement a function called `duplicates` that takes as an input a (tidy) dataframe `x`. Assume that `duplicates` receives a dataframe as returned from your Step 0 implementation of `tidy`. It then checks whether there are any duplicates in the dataset. Record the row ids of the observations being duplicates and have `duplicates` returns the list in the end. An empty list indicates the absence of duplicated observations."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5d3199cb48685917455f085c8d366844",
     "grade": false,
     "grade_id": "cell-7954cffea933a812",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-13T11:29:41.715331Z",
     "start_time": "2024-05-13T11:29:41.497147Z"
    }
   },
   "source": [
    "def duplicates(df):\n",
    "\n",
    "    \n",
    "    duplicates_rows = df.duplicated(keep = False)\n",
    "    duplicates_index_list = df.index[duplicates_rows].tolist()\n",
    "    duplicate = map(int, duplicates_index_list)\n",
    "    return list(duplicate)\n",
    "    raise NotImplementedError()\n",
    "\n",
    "\n",
    "duplicates(tidy(mn))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 3,\n",
       " 51,\n",
       " 52,\n",
       " 65,\n",
       " 66,\n",
       " 75,\n",
       " 76,\n",
       " 178,\n",
       " 179,\n",
       " 206,\n",
       " 207,\n",
       " 263,\n",
       " 264,\n",
       " 272,\n",
       " 273,\n",
       " 291,\n",
       " 292,\n",
       " 394,\n",
       " 395,\n",
       " 433,\n",
       " 434,\n",
       " 481,\n",
       " 482,\n",
       " 517,\n",
       " 518,\n",
       " 646,\n",
       " 647,\n",
       " 650,\n",
       " 651,\n",
       " 675,\n",
       " 676,\n",
       " 704,\n",
       " 705,\n",
       " 726,\n",
       " 727,\n",
       " 761,\n",
       " 762,\n",
       " 792,\n",
       " 793,\n",
       " 838,\n",
       " 839,\n",
       " 869,\n",
       " 870,\n",
       " 875,\n",
       " 876,\n",
       " 887,\n",
       " 888,\n",
       " 905,\n",
       " 906,\n",
       " 946,\n",
       " 947,\n",
       " 951,\n",
       " 952,\n",
       " 970,\n",
       " 971,\n",
       " 1007,\n",
       " 1008,\n",
       " 1056,\n",
       " 1057,\n",
       " 1090,\n",
       " 1091,\n",
       " 1164,\n",
       " 1165,\n",
       " 1179,\n",
       " 1180,\n",
       " 1229,\n",
       " 1230,\n",
       " 1299,\n",
       " 1300,\n",
       " 1369,\n",
       " 1370,\n",
       " 1380,\n",
       " 1381,\n",
       " 1392,\n",
       " 1393,\n",
       " 1448,\n",
       " 1449,\n",
       " 1475,\n",
       " 1476,\n",
       " 1560,\n",
       " 1561,\n",
       " 1570,\n",
       " 1571,\n",
       " 1573,\n",
       " 1574,\n",
       " 1592,\n",
       " 1593,\n",
       " 1601,\n",
       " 1602,\n",
       " 1615,\n",
       " 1616,\n",
       " 1637,\n",
       " 1638]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 119
  },
  {
   "cell_type": "code",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "81f1ddaa2595165edcbe3c3848bf1880",
     "grade": true,
     "grade_id": "cell-583bc8ab4ba38aa6",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-13T11:27:23.291253Z",
     "start_time": "2024-05-13T11:27:22.996175Z"
    }
   },
   "source": [
    "from nose.tools import assert_equal\n",
    "assert_equal(type(duplicates(tidy(mn))), list)\n"
   ],
   "outputs": [],
   "execution_count": 114
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8078773ced981185cbbd33775ad95033",
     "grade": false,
     "grade_id": "cell-b04e3f6689a78a44",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "-----\n",
    "## 4. Handling duplicate entries\n",
    "### 4.1. Code part\n",
    "Implement a function called `handling_duplicate_entries` for handling duplicate entries. Again, the function is assumed to receive a tidied data set as obtained from Step 0. It deduplicates the tidy data set. The function then returns the dataframe without duplicates."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "612e2d5322a7c96c67c1405ff80ebb36",
     "grade": false,
     "grade_id": "cell-f593e79eae8f4227",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-13T11:29:51.287578Z",
     "start_time": "2024-05-13T11:29:50.922705Z"
    }
   },
   "source": [
    "def handling_duplicate_entries(df):\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    df.drop_duplicates(inplace = True)\n",
    "    \n",
    "    return df\n",
    "    raise NotImplementedError()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 120
  },
  {
   "cell_type": "code",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "10bdb20c5d61c818cc5ff269c76ccb62",
     "grade": true,
     "grade_id": "cell-231217b55b6ef843",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-13T11:28:47.042404Z",
     "start_time": "2024-05-13T11:28:46.788979Z"
    }
   },
   "source": [
    "from nose.tools import assert_equal\n",
    "assert_equal(len(duplicates(handling_duplicate_entries(tidy(mn)))), 0)"
   ],
   "outputs": [],
   "execution_count": 118
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fb5d1538ad19f872fb94d62d81a42f23",
     "grade": false,
     "grade_id": "cell-8c4530b128b5c186",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 4.2. Analytical part\n",
    "Discuss the implications. \n",
    "\n",
    "- What are the benefits and disadvantages of the chosen duplicate definition and the chosen duplicate-handling technique?\n",
    "- Name and explain one alternative definition of (intra-source) duplicates for the given dataset!\n",
    "\n",
    "Write your answer in the markdown cell bellow. Do NOT delete or replace the answer cell with another one!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9e93305db24e2fc3800f252b797c2ad7",
     "grade": true,
     "grade_id": "cell-254db63097c3ed40",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
