{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f8e9fd436f8738876cded8d1bc870c35",
     "grade": false,
     "grade_id": "cell-2db14fa210da2ef0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-02T18:56:09.485745Z",
     "start_time": "2024-05-02T18:56:09.294713Z"
    }
   },
   "source": [
    "from nose.tools import assert_equal"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "08fecd06cada05dc2b74c825e68b8924",
     "grade": false,
     "grade_id": "cell-e37bf3469fc1e9d7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All). Do NOT add any cells to the notebook!\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or _YOUR ANSWER HERE_ , as well as your name and group below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Florian Ploder\"\n",
    "# Pls indicate your student id as a string, w/o the leading 'h'!\n",
    "student_id = \"12209427\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "98f4095b70e2e8a37536be022f0b7bcf",
     "grade": false,
     "grade_id": "cell-547da1b1777ed8e0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Assignment 3 (Individual)\n",
    "\n",
    "\n",
    "Continuing from Assignment 2, we will now further practice processing datasets.\n",
    "From what you have seen in the lecture, in this assignment you should practice the following steps:\n",
    "\n",
    "* basic dataset decription & assessing \"tidyness\"\n",
    "* filtering\n",
    "* sorting\n",
    "* aggregation\n",
    "\n",
    "using both \"pure\" Python and also using pandas. \n",
    "\n",
    "-----\n",
    "\n",
    "## Step 1a (4 points)\n",
    "\n",
    "Find a CSV dataset online (similar requirements apply as for Assignment 2), but additionally make sure that the dataset has \n",
    " * at least one non-numeric column (with a categorical variable), and\n",
    " * at least one column with numerical values.\n",
    "\n",
    "Note, as opposed to working in a group for Assignment 2, you are not allowed to use the same dataset, i.e., we expect everybody to find their own CSV file.\n",
    "\n",
    "Save the file into your data folder and name it __data_notebook-1_DataFile.csv__.\n",
    "\n",
    "*<b>ATTENTION</b>:* to avoid any unexpected errors when running your submission in our grading environment, we strongly recommend using an RFC-compliant CSV file encoded in `utf-8`: i.e., make sure that the CSV file uses ',' as a delimiter (if the original file doesn't, you may need to convert it first: i.e., our hidden tests assume that the code will work for any RFC-compliant CSV file with the delimiter ','.*).\n",
    "\n",
    "Using the CSV package, write a function `analyzeCSV` to return\n",
    "* the number of rows in the dataset (excl. the header row).\n",
    "* How many different __values__ and what __datatype__ appear per column in the CSV file.\n",
    "\n",
    "That is, the function should return a dictionary of the following structure:\n",
    "```\n",
    " {\n",
    "  \"rows\": ..., # the number of rows (integer)\n",
    "  \"columns\": ... # a list of pairs [ (v_1,dt_1) , (v_2,dt_2), ... (v_1,dt_1)]\n",
    " }\n",
    "```\n",
    "`(v_i,dt_i)` denotes the number of different values (`v_i`) and the datatype (`dt_i`) detected in column `i`.\n",
    "If you detect several different datatypes per column your function should return the value `\"object\"` for `dt_i`. Missing value notations like `NaN` should be considered as strings. Also, you do not have to specifically test for type `datetime`.\n",
    "<br><br>\n",
    "\n",
    "Additionally, we have uploaded a CSV testfile in `unit3/data/testfile.csv` that you can use to check your solution against our target in the visible test cases. Make sure to put it in your `/data/` folder, to make the respective tests work; it also recommended to take a look at the visible test case results for all tasks, to see how you should format your output.\n",
    "\n",
    "__Hint__: For (heuristic) datatype detection per column, please use/adapt the function `convert()` from the notebook `unit3/00_value-transformation.ipynb` from the lecture, i.e., possible return values besides the string `\"object\"` should be the return value of the function `type()` applied to the heuristically converted values in the column using `convert()`.\n",
    "\n",
    "__Caution__: Do not import any other packages than those mentioned in lecture examples."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "71574f43d96a6e50826a4c3f5d01213d",
     "grade": false,
     "grade_id": "cell-888abc9fb6a6b742",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2024-04-25T21:29:00.700119Z",
     "start_time": "2024-04-25T21:28:59.101839Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "currency = \"./data/data_notebook-1_currency.csv\"\n",
    "velo_fuss_count = \"./data/data_notebook-1_velo_fuss_count.csv\"\n",
    "filePath = \"./data/data_notebook-1_velo_fuss_count.csv\"\n",
    "testfile = \"./data/testfile.csv\""
   ],
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[0;32m      4\u001B[0m currency \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./data/data_notebook-1_currency.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m----> 5\u001B[0m velo_fuss_count, filePath \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./data/data_notebook-1_velo_fuss_count.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m      6\u001B[0m testfile \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./data/testfile.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "\u001B[1;31mValueError\u001B[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d8887ebd91b2c096e9badab37fd8e2cf",
     "grade": false,
     "grade_id": "cell-2b88d1e6c1925d1c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Define a function to attempt type conversion of values using specified heuristics.\n",
    "def convert(value):\n",
    "    heuristics = [int, float]\n",
    "    result = []\n",
    "    for el in value:\n",
    "        converted = False\n",
    "        for typecast in heuristics:\n",
    "            try:\n",
    "                result.append(type(typecast(el)).__name__)\n",
    "                converted = True\n",
    "                break\n",
    "            except:\n",
    "                continue\n",
    "        if not converted:\n",
    "            result.append(type(el).__name__)\n",
    "    return result\n",
    "\n",
    "# Analyze a CSV file for unique values and data types in each column.\n",
    "def analyzeCSV(filePath):    \n",
    "    rows = -1  # Initialize to -1 to account for the header row.\n",
    "    list_csv = []  # To store the contents of the CSV.\n",
    "    v = []  # To hold counts of unique values per column.\n",
    "    dt = []  # To store detected data types for each column.\n",
    "    v_dt = []  # To pair counts of unique values with data types.\n",
    "\n",
    "    # Read the CSV file.\n",
    "    with open(filePath) as csvfile:\n",
    "        data = csv.reader(csvfile, delimiter=\",\")\n",
    "        for row in data:\n",
    "            rows += 1\n",
    "            list_csv.append(row)\n",
    "\n",
    "    # Transpose rows to columns.\n",
    "    list_t = list(zip(*list_csv[1:]))\n",
    "    \n",
    "    # Count unique values for each column.\n",
    "    for i, l in enumerate(list_t):\n",
    "        v.append(len(set(l)))\n",
    "        \n",
    "    # Determine the data type for each column.\n",
    "    types = [convert(a) for a in list_t]\n",
    "    for l in types:\n",
    "        if len(set(l)) == 1:\n",
    "            dt.extend(set(l))\n",
    "        else:\n",
    "            dt.append(\"object\")\n",
    "        \n",
    "    # Combine the unique counts and data types.\n",
    "    for length in range(len(list_t)):\n",
    "        v_dt.append((v[length], dt[length]))\n",
    "    \n",
    "    # Return the results.\n",
    "    result = {\"rows\": rows, \"columns\": v_dt}\n",
    "    return result\n",
    "\n",
    "\n",
    "#analyzeCSV(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "86276cf50755139e53f8a576fded20dd",
     "grade": false,
     "grade_id": "cell-ab8cd6999e00795a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(analyzeCSV(filePath)), dict)\n",
    "assert_equal(len(analyzeCSV(filePath)), 2)\n",
    "assert_equal(analyzeCSV(testfile), {'rows': 12, 'columns': [(3, 'str'), (3, 'int'), (2, 'str'), (6, 'int')]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "93efdfcafa6e17c15b02590fde956c51",
     "grade": true,
     "grade_id": "cell-8e80d24157bdcf2b",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Do not edit or delete this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f9c1747cc3988085a0e3c8d16eef427",
     "grade": true,
     "grade_id": "cell-6f0365f798ba7e41",
     "locked": true,
     "points": 1.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0# Do not edit or delete this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cb436adc00edcf8f3658087de2cd0c20",
     "grade": true,
     "grade_id": "cell-17188db36ea1190b",
     "locked": true,
     "points": 1.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Do not edit or delete this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f0b53bb58be6eb96a6d3d08cb67f2ee6",
     "grade": true,
     "grade_id": "cell-9d91010f5f3041af",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Do not edit or delete this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "678785b1463c6887e7d54045455acc1e",
     "grade": false,
     "grade_id": "cell-0601eda65c85a474",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now (possibly with some more manual inspection) answer the following questions:\n",
    "* Which types of variables appear in this dataset? For each variable, indicate whether\n",
    "  *  it is numerical or categorical; for numeric values, specify whether the scale is nominal, ordinal, interval, or ratio.\n",
    "  *  it is an identifier, a dimension, or a measurement.  \n",
    "* How would you describe an \"observation\" in this dataset?\n",
    "* Is the dataset tidy?\n",
    "* If not, why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "95b0f6134ade6ae1b5f2bc193b820d77",
     "grade": true,
     "grade_id": "cell-f2d935f6c5393e81",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "The dataset used is a slight variation from the original one found on data.europa.eu (Amt für Mobilität, 'Traffic count data Velos and pedestrians', 2019 (updated 2024-04-23), accessed 2024-04-25, http://data.europa.eu/88u/dataset/100013-kanton-basel-stadt~~1). ~~I edited the data to fit the requirements of the task because the original dataset was too large. Here are the steps I took. (I did not change the values of the variables, except for summing up all Total values, so the tidiness of the dataset remained the same):\n",
    "\n",
    "-  I grouped all data by their SiteCode, TrafficType and DayOfYear and summed up all values from Total. Due to this transformation, some columns were removed because they were too detailed.\n",
    "-  I sorted the data by their SiteCode and DayOfYear.\n",
    "-  I converted the CSV file into an RFC-compliant CSV file, with a comma delimiter and UTF-8 encoding.\n",
    "-  I removed some data from the bottom to ensure the dataset contained fewer than 10,000 rows.\n",
    "\n",
    "generelly Code (used more iterations because dataset was to large to handle all at onces): \n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "with open('original.csv') as reader:\n",
    "    df = pd.read_csv(reader)\n",
    "\n",
    "df_grouped = df.groupby([\"SiteCode\", \"SiteName\", \"Date\", \"TrafficType\", \"Year\", \"Month\", \"Day\", \"Weekday\", \"DayOfYear\", \"Zst_id\"], as_index=False)['Total'].sum()\n",
    "custom_headers = [\"SiteCode\", \"SiteName\", \"Date\", \"TrafficType\", \"Year\", \"Month\", \"Day\", \"Weekday\", \"DayOfYear\", \"Zst_id\", \"Total\"]\n",
    "df_grouped.columns = custom_headers\n",
    "sorted_df = df_grouped.sort_values([\"SiteCode\", \"TrafficType\", \"DayOfYear\"], ascending=True)\n",
    "\n",
    "with open('edited.csv', 'w') as writer:\n",
    "    sorted_df.to_csv(writer, index=False)\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "**Variables in the data set:**\n",
    "| Variable | Type | Description |\n",
    "| ----------- | ----------- | ----------- | \n",
    "SiteCode | Numerical - Nominal | Identifier\n",
    "SiteName | Categorical - Nominal | Identifier\n",
    "Date | Categorical - Interval | Dimension\n",
    "TrafficType | Categorical - Nominal | Dimension\n",
    "Year | Numerical - Interval | Dimension\n",
    "Month | Numerical - Ordinal | Dimension\n",
    "Day | Numerical - Ordinal | Dimension\n",
    "Weekday | Numerical - Ordinal | Dimension\n",
    "DayOfYear | Numerical - Ordinal | Dimension\n",
    "Zst_id | Numerical - Nominal | Identifier\n",
    "Total | Numerical - Ratio | Measurement\n",
    "\n",
    "**\"observation\":**\n",
    "\n",
    "In this dataset, an observation represents a record of traffic (\"TrafficType\") for a particular site (\"SiteName\" and/or \"SiteCode\") on a specific date (\"Date\"). Each entry contains detailed temporal information (\"Year\", \"Month\", \"Day\", \"Weekday\", \"DayOfYear\") along with the total count of traffic events (\"Total\") on that date.\n",
    "\n",
    "**Tidiness:**\n",
    "\n",
    "The dataset seems pretty tidy because each variable is in its own column, every single observation gets its own row, and every type of data we're looking at has its own table. But, the \"Date\" column is pretty useless. It's just one column, but we could break it down into \"Year,\" \"Month,\" and \"Day\" for a more detailed look. That said, those columns are already there separately, so the \"Date\" column might be a bit extra unless if we don't actually need the date in a dd.mm.yyyy format and are to lazy to extract it from the individual columns.\n",
    "\n",
    "**Conclusion**\n",
    "\n",
    "Overall, the dataset is very tidy, which is no surprise considering it's from Switzerland. The formulas written in the steps below are quite usefull for further analysis but some methods have to be adjusted to use it to analyse the data. For example using the left-most (numerical) column doesn't make sense in many datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7816728ad695a6e37bbab858b740b530",
     "grade": false,
     "grade_id": "cell-92fae8cb742fa6bd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Step 1b (2 points)\n",
    "\n",
    "Now, perform the same steps you solved in 1a using pandas, i.e., read in the CSV file and write the function `pandalyzeCSV` that computes the same structure as defined in 1a.\n",
    "\n",
    "__Hint:__ pandas dataframes provide the useful function `nunique()` to compute the number of unique values in a column (`v_i`) as well as the attribute  `dtypes` to get the column datatypes (`dt_i`), which you should use. This means, that the result returned by this solution using pandas might be slighlty different than the solution of step 1a.\n",
    "\n",
    "Using the test CSV provided by us, your solution for `pandalyzeCSV` should result in this dictionary:\n",
    "\n",
    "`{'rows': 12, 'columns': [(3, dtype('O')), (3, dtype('int64')), (2, dtype('O')), (6, dtype('int64'))]})`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "30297602e35a906c835ccf0fad335bd0",
     "grade": false,
     "grade_id": "cell-a8850bfaa5ec668e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def pandalyzeCSV(filePath):\n",
    "    # YOUR CODE HERE \n",
    "    df = pd.read_csv(filePath)\n",
    "        \n",
    "    result = {\n",
    "        \"rows\": len(df.index),\n",
    "        \"columns\": [(len(df[column].unique()), df[column].dtype) for column in df.columns]\n",
    "        }\n",
    "    \n",
    "    \"\"\"\n",
    "    the following code lead to the short version on top by learning more about list comprehensions\n",
    "    v = []\n",
    "    dt =[]\n",
    "    v_dt = []\n",
    "    \n",
    "    for column in df.columns:\n",
    "        v.append(len(df[column].unique()))\n",
    "    \n",
    "    dt.append(list(df.dtypes))\n",
    "      \n",
    "    for length, item in enumerate(dt):\n",
    "        v_dt.append((v[length],dt[length]))\n",
    "    \"\"\"\n",
    "\n",
    "    return result\n",
    "    raise NotImplementedError()\n",
    "\n",
    "#pandalyzeCSV(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "64c4d7ff0b546bf9409b7180e7f90baa",
     "grade": false,
     "grade_id": "cell-c27d203b1fadc3ee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(pandalyzeCSV(filePath)), dict)\n",
    "assert_equal(len(pandalyzeCSV(filePath)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d39082e6b80cd58973070e4e349010fd",
     "grade": true,
     "grade_id": "cell-d541682480f3f585",
     "locked": true,
     "points": 0.65,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Do not edit or delete this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "39dc27de1abab0dc9b3d343ab2fa74b4",
     "grade": true,
     "grade_id": "cell-b79536967a14a331",
     "locked": true,
     "points": 0.65,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Do not edit or delete this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "368804277ab7426871cd584125f05b27",
     "grade": true,
     "grade_id": "cell-5d9bc50d82c95c93",
     "locked": true,
     "points": 0.7,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Do not edit or delete this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b48d6f348fe4290687d1930dedb8c2e0",
     "grade": false,
     "grade_id": "cell-763a3cdfc1a5447d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Step 2a Filtering (2 points)\n",
    "\n",
    "Using pure Python, i.e. NOT pandas, write the function csvFilter, which should:\n",
    "\n",
    "* convert the CSV to a list of lists, where each row becomes an inner list;\n",
    "* filter the rows of the dataset by the <b>numeric</b> column with the most unique values (if there are several columns with the same number of unique values, take the left-most of those) by showing all rows where the value of that column is greater than the median of the column;\n",
    "* return the list of lists containing only the filtered rows and no header!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fc6790cd61f2e6a3fb086f7005be434c",
     "grade": false,
     "grade_id": "cell-3e8023888dd8a9c3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def getmedian(input_list):\n",
    "    l = len(input_list)\n",
    "    if l % 2 == 0:\n",
    "        median = (input_list[int(l/2)-1] + input_list[int(l/2)]) / 2   \n",
    "    else:\n",
    "        median = input_list[int(l/2)]\n",
    "    return median\n",
    "\n",
    "def csvFilter(filePath): \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    with open(filePath) as csvfile:\n",
    "        data = csv.reader(csvfile)\n",
    "        csv_list = list(data)\n",
    "\n",
    "    analyze = analyzeCSV(filePath)\n",
    "    \n",
    "    max_v = 0\n",
    "    max_col = None\n",
    "    \n",
    "    # Get a numeric column with the most unique values using the analyzeCSV function.\n",
    "    try: \n",
    "        for i, (v,dt) in enumerate(analyze[\"columns\"]):            \n",
    "            if dt in [\"int\", \"float\", \"complex\"]:\n",
    "                if max_v < v:\n",
    "                    max_v = v\n",
    "                    max_col = i\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    \n",
    "    # To calculate median collect all the values in a list, sort it and use the formula for the median\n",
    "    values_column = [float(element[max_col]) for element in csv_list[1:]]\n",
    "    values_column.sort()    \n",
    "\n",
    "    median = getmedian(values_column)\n",
    "    \n",
    "    # Filter the list with this list comprehension wich prints only the inner lists where the value of the defined column is bigger than the median.\n",
    "    filtered_list = [inner_l for inner_l in csv_list[1:] if float(inner_l[max_col]) > median]\n",
    "    \n",
    "    return filtered_list\n",
    "    raise NotImplementedError()\n",
    "\n",
    "#csvFilter(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7c77a5fafdc44651f1008a1093fde50f",
     "grade": false,
     "grade_id": "cell-bd52f1acb2358696",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(csvFilter(testfile)), list)\n",
    "assert_equal(type(csvFilter(filePath)), list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b636aa4703fc63e580d6ea6289030bfb",
     "grade": true,
     "grade_id": "cell-9654f52c7a018b56",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Do not edit or delete this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a3e80ece02f14a80ad12c3a79a940054",
     "grade": true,
     "grade_id": "cell-1d85962f12d23198",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Do not edit or delete this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b802fc8f0eea186ef1e48f3fec3c4038",
     "grade": true,
     "grade_id": "cell-2176472d26220b38",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Do not edit or delete this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e5e2927d1cc5eab17075cf162b6ae8a7",
     "grade": false,
     "grade_id": "cell-ccb23da90625904d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Step 2b Filtering - pandas (2 points)\n",
    "\n",
    "Now, again using pandas, write the function `pandasFilter` to:\n",
    "* convert the dataset to a pandas dataframe\n",
    "* filter the rows of the dataset by the same condition as for 2a:\n",
    "* return the pandas dataframe only containing the filtered rows! The header and index can remain the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "237a0d5715d0811eba48932a669fdc81",
     "grade": false,
     "grade_id": "cell-4822ef9f00f9e26c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def pandasFilter(filePath):   \n",
    "    # YOUR CODE HERE\n",
    "    df = pd.read_csv(filePath)\n",
    "    \n",
    "    max_v = 0\n",
    "    max_col = None\n",
    "    # Get column name with the most unique numeric values.\n",
    "    for column in df.columns:\n",
    "        if pd.api.types.is_numeric_dtype(df[column]):\n",
    "            v = len(df[column].unique())\n",
    "            if max_v < v:\n",
    "                max_v = v\n",
    "                max_col = column\n",
    "\n",
    "    \n",
    "    median = df[max_col].median()\n",
    "    \n",
    "    filtered_df = df[df[max_col] > median]\n",
    "     \n",
    "    return filtered_df\n",
    "    raise NotImplementedError()\n",
    "\n",
    "#pandasFilter(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "83b4a16035aedc416d71a41d57095402",
     "grade": false,
     "grade_id": "cell-4e7f425477a41440",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(pandasFilter(testfile)), pd.DataFrame)\n",
    "assert_equal(type(pandasFilter(filePath)), pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cb0b915afd420efdb4f6f05f8c050b9c",
     "grade": true,
     "grade_id": "cell-28dc4497d108354e",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Do not edit or delete this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3274f558bf1a4461c6f375e5f99057b0",
     "grade": true,
     "grade_id": "cell-5276ad128dffda38",
     "locked": true,
     "points": 0.65,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Do not edit or delete this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5f47b45ff205afcbda750cf4e39e7e4b",
     "grade": true,
     "grade_id": "cell-6b3f524815325bec",
     "locked": true,
     "points": 0.65,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Do not edit or delete this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a7d30385341fd02ff97c17442532f45d",
     "grade": true,
     "grade_id": "cell-237f26bc2a01a5ad",
     "locked": true,
     "points": 0.7,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Do not edit or delete this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0cea5c420863efd88aaa282dd5fdc530",
     "grade": false,
     "grade_id": "cell-8c1be8eef825aa09",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Step 3a Sorting (2 points)\n",
    "\n",
    "Using pure Python, i.e. NOT using pandas:\n",
    "* define a function sortCSV(filePath) which sorts the rows of your csv file by the left-most numerical column in descending order of values. You do not need to sort values in any other column.\n",
    "* The function takes *filePath* as input (which you have already defined above).\n",
    "* Your function should return the sorted contents of the CSV file as a list of lists.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f94e91f53ae35128b19e4c672daa6977",
     "grade": false,
     "grade_id": "cell-987ea095365b9681",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def sortCSV(filePath):\n",
    "    # Read CSV file into a list of rows.\n",
    "    with open(filePath) as csvfile:\n",
    "        data = csv.reader(csvfile)\n",
    "        csv_list = list(data)\n",
    "        \n",
    "    # Analyze the CSV to get data types for each column.\n",
    "    analyze = analyzeCSV(filePath)\n",
    "    \n",
    "    # Attempt to find the first numerical column to sort by.\n",
    "    try: \n",
    "        for i, (v, dt) in enumerate(analyze[\"columns\"]):            \n",
    "            if dt in [\"int\", \"float\", \"complex\"]:\n",
    "                left_col = i\n",
    "                break\n",
    "    except Exception as e:\n",
    "        # If an error occurs or no numerical column is found, skip sorting.\n",
    "        pass\n",
    "    \n",
    "    # Sort the CSV based on the first found numerical column, in descending order.\n",
    "    sorted_list = [csv_list[0]] + sorted(csv_list[1:], key=lambda x: x[left_col], reverse=True)\n",
    "    \n",
    "    return sorted_list\n",
    "\n",
    "\n",
    "#sortCSV(testfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "02b5a751ad0c518a29df6aa0366e8515",
     "grade": false,
     "grade_id": "cell-a334c571e3d33bf1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(sortCSV(testfile)), list)\n",
    "assert_equal(type(sortCSV(filePath)), list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f6564053f8f7671c1d93e7e08f434be7",
     "grade": true,
     "grade_id": "cell-936c7117690f7f32",
     "locked": true,
     "points": 0.65,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Do not edit or delete this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b189e7de25513e2b8b977669d266db92",
     "grade": true,
     "grade_id": "cell-53d2f131956b41ab",
     "locked": true,
     "points": 0.65,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Do not edit or delete this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "41ff0a45cc4935fb8bfa7bc2e76c21a7",
     "grade": true,
     "grade_id": "cell-c495b4f398bb09f7",
     "locked": true,
     "points": 0.7,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Do not edit or delete this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "43e04844dae1ff76c83eff49c28a982a",
     "grade": false,
     "grade_id": "cell-1eff3872e1df78c6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Step 3b Sorting - pandas (2 points)\n",
    "\n",
    "Now, again using pandas, \n",
    "* define a similar function PandasSortCSV(filePath) which sorts the rows of the dataset by the same columns as in 3a, again in descending order of values. \n",
    "* This time, your function should return a pandas dataframe.\n",
    "  \n",
    "*Hint*: There is no need to reset the index, just leave it as it is.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "433a3e7a697b9d130d4bd0046795ef11",
     "grade": false,
     "grade_id": "cell-e63244f3196ef27f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def PandasSortCSV(filePath):\n",
    "    # Load CSV file into a DataFrame.\n",
    "    df = pd.read_csv(filePath)\n",
    "    \n",
    "    left_col = None\n",
    "    \n",
    "    # Identify the first numeric column to use as the sorting key.\n",
    "    for column in df.columns:\n",
    "        if pd.api.types.is_numeric_dtype(df[column]):\n",
    "            left_col = column\n",
    "            break\n",
    "    \n",
    "    # Sort the DataFrame by the identified column in descending order.\n",
    "    sorted_df = df.sort_values(by=left_col, ascending=False)\n",
    "    \n",
    "    return sorted_df                \n",
    "    raise NotImplementedError()\n",
    "    \n",
    "#PandasSortCSV(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "63d9f55b9ae1bca8ba535fbdce73c53c",
     "grade": false,
     "grade_id": "cell-76f4d0fa5f0d1c49",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(isinstance(PandasSortCSV(testfile), pd.DataFrame), True)\n",
    "assert_equal(isinstance(PandasSortCSV(filePath), pd.DataFrame), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f48eb6b1fb4bff5c89d082c6ef99bf22",
     "grade": true,
     "grade_id": "cell-e36efdcd51d437d5",
     "locked": true,
     "points": 0.65,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Do not edit or delete this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3f6cfccd7f0e2a36592a1ac7eecb832b",
     "grade": true,
     "grade_id": "cell-547acfb340211741",
     "locked": true,
     "points": 0.65,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Do not edit or delete this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4443b482c755cb78cbff0dd39c859b7e",
     "grade": true,
     "grade_id": "cell-7bcd340aeb331e23",
     "locked": true,
     "points": 0.7,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Do not edit or delete this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a393d3978fbc859f4c646012704c184f",
     "grade": false,
     "grade_id": "cell-b64c2a5902f2cd4e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Step 4a Aggregation and Grouping (4 points)\n",
    "\n",
    "Using pure Python, i.e. NOT using pandas define a function `aggregateCSV(filePath)` which does the following:\n",
    "* takes the left-most numeric column _X_ and the left-most non-numeric column _Y_ and\n",
    "* calculates the __average (mean)__ of the values in column _X_ for each value in column _Y_.\n",
    "\n",
    "Your function should return a dictionary with the unique values of the non-numeric column as keys and the averages (per group) of the numeric column as values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "decebefd5ef7528eeaab366c68640f59",
     "grade": false,
     "grade_id": "cell-af18f5282baa2eb7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def aggregateCSV(filePath):    \n",
    "    # YOUR CODE HERE    \n",
    "    with open(filePath) as csvfile:\n",
    "        data = csv.reader(csvfile)\n",
    "        csv_list = list(data)\n",
    "     \n",
    "    # Find most-left numeric column and most-left non-numeric column using analyzeCSV function and its \"columns\" data.\n",
    "    analyze = analyzeCSV(filePath)\n",
    "    nn_col, n_col = None, None\n",
    "    try: \n",
    "        for i, (v,dt) in enumerate(analyze[\"columns\"]):            \n",
    "            if dt in [\"int\", \"float\", \"complex\"]:\n",
    "                if n_col is None:\n",
    "                    n_col = i\n",
    "            elif nn_col is None:\n",
    "                nn_col = i\n",
    "            elif nn_col and n_col:\n",
    "                break            \n",
    "    except Exception as e:\n",
    "        pass\n",
    "    \n",
    "    # Create dictionaries result (with each unique value as key and sum up all values) and count (with each unique values key and how often it appears).\n",
    "    result = {}\n",
    "    count = {}\n",
    "    \n",
    "    for row in csv_list[1:]:\n",
    "        nn_value = row[nn_col]\n",
    "        n_value = float(row[n_col])\n",
    "        \n",
    "        if nn_value in result:\n",
    "            result[nn_value] += n_value\n",
    "            count[nn_value] += 1\n",
    "        else:\n",
    "            result[nn_value] = n_value\n",
    "            count[nn_value] = 1\n",
    "    \n",
    "    # Divide the sum of all values of each key with the count of each key to get the mean.\n",
    "    for key in result:\n",
    "        result[key] /= count[key]\n",
    "    \n",
    "    return result   \n",
    "    raise NotImplementedError()\n",
    "    \n",
    "#aggregateCSV(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6f0addb5e3ee6b693a929d2d12433566",
     "grade": false,
     "grade_id": "cell-342b283e07825927",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(aggregateCSV(testfile)), dict)\n",
    "assert_equal(type(aggregateCSV(filePath)), dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1425de41fcc70f4d8f8c3ea8904a5eef",
     "grade": true,
     "grade_id": "cell-499534f29957f9d3",
     "locked": true,
     "points": 1.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Do not edit or delete this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bbdda5b30879c94ebdb2896d3659a0f1",
     "grade": true,
     "grade_id": "cell-978ae498cda7f990",
     "locked": true,
     "points": 1.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Do not edit or delete this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2a3bea605400902c1b8bd3250a2fc915",
     "grade": true,
     "grade_id": "cell-d639df8ce5796215",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Do not edit or delete this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fc2a0c21f0dd864d218a3c59ebc029cf",
     "grade": false,
     "grade_id": "cell-ddbe334d3b102c49",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Step 4b Aggregation and Grouping - pandas (2 points)\n",
    "\n",
    "Now, again using pandas, do the same as in 4a and call the function `PandasAggregateCSV` this time. It should return a pandas dataframe. The columns do not have to be renamed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1941355b2a28767d087f43d822d7848f",
     "grade": false,
     "grade_id": "cell-95103e5f3482a467",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def PandasAggregateCSV(filePath):\n",
    "    # YOUR CODE HERE\n",
    "    df = pd.read_csv(filePath)\n",
    "    \n",
    "    # Find most-left numeric column and most-left non-numeric column using if statements.\n",
    "    nn_col, n_col = None, None\n",
    "    for column in df.columns:\n",
    "        if pd.api.types.is_numeric_dtype(df[column]):\n",
    "            if n_col is None:\n",
    "                n_col = column\n",
    "        elif nn_col is None:\n",
    "            nn_col = column\n",
    "\n",
    "    result = df.groupby(nn_col)[n_col].mean()\n",
    "    result_df = pd.DataFrame(result)\n",
    "    \n",
    "    return result_df\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "#PandasAggregateCSV(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa639264dd70422956e559558202a36b",
     "grade": false,
     "grade_id": "cell-e97bad506966067e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(isinstance(PandasAggregateCSV(testfile), pd.DataFrame), True)\n",
    "assert_equal(isinstance(PandasAggregateCSV(filePath), pd.DataFrame), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3f86757d0607b62f32fde0b05e90d223",
     "grade": true,
     "grade_id": "cell-c3d99dc4c712616d",
     "locked": true,
     "points": 0.65,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Do not edit or delete this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d1a5bd529c8416746dcb26b7947c6fd8",
     "grade": true,
     "grade_id": "cell-12eae7213662b019",
     "locked": true,
     "points": 0.65,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Do not edit or delete this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3e2a951bb4ea2c3eeb9a105e5917f234",
     "grade": true,
     "grade_id": "cell-f6e580fb4e081e27",
     "locked": true,
     "points": 0.7,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Do not edit or delete this cell"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
